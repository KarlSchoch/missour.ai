{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e9ef80-c39f-4830-9978-863f672d9de1",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bf4e6c-73b1-489a-8fb3-f98930c2a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53285b10-b2a9-493c-b281-e9a3652a8d50",
   "metadata": {},
   "source": [
    "# Define Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a4dd9af6-78fd-4a6d-8a7c-2a93a355ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>manual_Information Technology_tag</th>\n",
       "      <th>gpt-4.1-mini_Information Technology_tag</th>\n",
       "      <th>manual_relevant_text</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Model</th>\n",
       "      <th>Chunking Strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>to the NDI on page 18 for $355,000 fund switch...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>so let's turn to page 84, this is an NDI for C...</td>\n",
       "      <td>ded</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>recursive-character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>260</td>\n",
       "      <td>is. Is it number of students who have done X, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>I have a team that does programmatic monitorin...</td>\n",
       "      <td>dss-non-medicaid-pt2</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>recursive-character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>no longer include the cost for security servic...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>So historically, a vendor communication servic...</td>\n",
       "      <td>sa-dolir</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>recursive-character</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_id                                         chunk_text  \\\n",
       "0        46  to the NDI on page 18 for $355,000 fund switch...   \n",
       "1       260  is. Is it number of students who have done X, ...   \n",
       "2        58  no longer include the cost for security servic...   \n",
       "\n",
       "   manual_Information Technology_tag  gpt-4.1-mini_Information Technology_tag  \\\n",
       "0                               True                                    False   \n",
       "1                               True                                    False   \n",
       "2                               True                                    False   \n",
       "\n",
       "                                manual_relevant_text            Transcript  \\\n",
       "0  so let's turn to page 84, this is an NDI for C...                   ded   \n",
       "1  I have a team that does programmatic monitorin...  dss-non-medicaid-pt2   \n",
       "2  So historically, a vendor communication servic...              sa-dolir   \n",
       "\n",
       "          Model    Chunking Strategy  \n",
       "0  gpt-4.1-mini  recursive-character  \n",
       "1  gpt-4.1-mini  recursive-character  \n",
       "2  gpt-4.1-mini  recursive-character  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_summary_df, aggregate_summary_df, deep_dive_data = evaluate_model_performance()\n",
    "deep_dive_data['false_negatives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99d321ef-c771-440b-a1ee-edb667fb274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(\n",
    "    data_dir:str = '../data',\n",
    "    topic:str = 'Information Technology',\n",
    "    model_names:list = ['gpt-4.1-nano', 'gpt-4.1-mini'],\n",
    "    chunking_strategies:list = ['recursive-character', 'semantic-percentile'],\n",
    "    transcripts:list = ['ded', 'dss-non-medicaid-pt2', 'sa-dolir'],\n",
    "    deep_dive_models:list= ['gpt-4.1-mini'],\n",
    "    deep_dive_chunking_strategies=['recursive-character']\n",
    "):\n",
    "    full_summary_data = []\n",
    "\n",
    "    deep_dive_data = {\n",
    "        'false_positives': [],\n",
    "        'false_negatives': []\n",
    "    }\n",
    "\n",
    "    for transcript in transcripts:\n",
    "        for strategy in chunking_strategies:\n",
    "            # Construct search path for matching CSVs\n",
    "            search_path = f'{data_dir}/{transcript}-chunked-{strategy}-tagged.csv'\n",
    "            matching_files = glob.glob(search_path)\n",
    "\n",
    "            for file_path in matching_files:\n",
    "                df = pd.read_csv(file_path)\n",
    "  \n",
    "                for model in model_names:\n",
    "                    manual_tag_col = f\"manual_{topic}_tag\"\n",
    "                    model_tag_col = f\"{model}_{topic}_tag\"\n",
    "                    model_conf_col = f\"{model}_{topic}_tag_confidence\"\n",
    "                    model_rel_text_col = f\"{model}_{topic}_tag_relevant_section\"\n",
    "\n",
    "                    if manual_tag_col not in df.columns or model_tag_col not in df.columns:\n",
    "                        continue  # Skip if necessary columns are missing\n",
    "\n",
    "                    total = len(df)\n",
    "                    correct = (df[manual_tag_col] == df[model_tag_col]).sum()\n",
    "                    true_negatives = ((df[manual_tag_col] == False) & (df[model_tag_col] == False)).sum()\n",
    "                    false_positives = ((df[manual_tag_col] == False) & (df[model_tag_col] == True)).sum()\n",
    "                    false_negatives = ((df[manual_tag_col] == True) & (df[model_tag_col] == False)).sum()\n",
    "                    true_positives = ((df[manual_tag_col] == True) & (df[model_tag_col] == True)).sum()\n",
    "\n",
    "                    true_positive_rate = true_positives / (true_positives + false_negatives)\n",
    "                    true_negative_rate = true_negatives / (true_negatives + false_positives)\n",
    "                    false_positive_rate = false_positives / (false_positives + true_negatives)\n",
    "                    false_negative_rate = false_negatives / (true_positives + false_negatives)\n",
    "                    f1_score = (2 * true_positives) / ( (2 * true_positives) + false_positives + false_negatives)\n",
    "  \n",
    "                    full_summary_data.append({\n",
    "                        \"Transcript\": transcript,\n",
    "                        \"Chunking Strategy\": strategy,\n",
    "                        \"Model\": model,\n",
    "                        \"Total Chunks\": total,\n",
    "                        \"Correct Classifications\": correct,\n",
    "                        \"Accuracy Rate\": correct / total if total else None,\n",
    "                        \"True Positives\": true_positives,\n",
    "                        \"True Positive Rate\": true_positive_rate,\n",
    "                        \"True Negatives\": true_negatives,\n",
    "                        \"True Negative Rate\": true_negative_rate,\n",
    "                        \"False Positives\": false_positives,\n",
    "                        \"False Positive Rate\": false_positive_rate,\n",
    "                        \"False Negatives\": false_negatives,\n",
    "                        \"False Negative Rate\": false_negative_rate,\n",
    "                        \"F1 Score\": f1_score,\n",
    "                    })\n",
    "\n",
    "                    # Only build deep dive views for selected models and strategies\n",
    "                    if model in deep_dive_models and strategy in deep_dive_chunking_strategies:\n",
    "                        # False Positives\n",
    "                        fp_rows = df[(df[manual_tag_col] == False) & (df[model_tag_col] == True)][[\n",
    "                            'chunk_id', 'chunk_text', manual_tag_col, model_tag_col, model_rel_text_col\n",
    "                        ]].copy()\n",
    "                        fp_rows['Transcript'] = transcript\n",
    "                        fp_rows['Model'] = model\n",
    "                        fp_rows['Chunking Strategy'] = strategy\n",
    "                        deep_dive_data['false_positives'].append(fp_rows)\n",
    "\n",
    "                        # False Negatives\n",
    "                        fn_rows = df[(df[manual_tag_col] == True) & (df[model_tag_col] == False)][[\n",
    "                            'chunk_id', 'chunk_text', manual_tag_col, model_tag_col, 'manual_relevant_text'\n",
    "                        ]].copy()\n",
    "                        fn_rows['Transcript'] = transcript\n",
    "                        fn_rows['Model'] = model\n",
    "                        fn_rows['Chunking Strategy'] = strategy\n",
    "                        deep_dive_data['false_negatives'].append(fn_rows)\n",
    "\n",
    "    full_summary_df = pd.DataFrame(full_summary_data)\n",
    "    full_summary_df = full_summary_df.sort_values(by=[\"Model\", \"Chunking Strategy\", \"Transcript\"])\n",
    "\n",
    "    # Create Model Level Summary DF across all the transcripts\n",
    "    ## Pull out the relevant columns \n",
    "    aggregate_summary_df = full_summary_df[\n",
    "        ['Model', 'Chunking Strategy', 'Total Chunks', 'Correct Classifications', 'True Positives', 'True Negatives', 'False Positives', 'False Negatives']\n",
    "    ]\n",
    "    ## Group by the Model and Chunking Strategy columns and aggregate the counting numbers\n",
    "    aggregate_summary_df = aggregate_summary_df.groupby(['Model', 'Chunking Strategy']).sum()\n",
    "    ## Calculate the statistics\n",
    "    aggregate_summary_df['Accuracy'] = aggregate_summary_df['Correct Classifications'] / aggregate_summary_df['Total Chunks']\n",
    "    aggregate_summary_df['True Positive Rate'] = aggregate_summary_df['True Positives'] / (aggregate_summary_df['True Positives'] + aggregate_summary_df['False Negatives'])\n",
    "    aggregate_summary_df['True Negative Rate'] = aggregate_summary_df['True Negatives'] / (aggregate_summary_df['True Negatives'] + aggregate_summary_df['False Positives'])\n",
    "    aggregate_summary_df['False Positive Rate'] = aggregate_summary_df['False Positives'] / (aggregate_summary_df['False Positives'] + aggregate_summary_df['True Negatives'])\n",
    "    aggregate_summary_df['False Negative Rate'] = aggregate_summary_df['False Negatives'] / (aggregate_summary_df['True Positives'] + aggregate_summary_df['False Negatives'])\n",
    "    aggregate_summary_df['F1 Score'] = (2 * aggregate_summary_df['True Positives']) / ( (2 * aggregate_summary_df['True Positives']) + aggregate_summary_df['False Positives'] + aggregate_summary_df['False Negatives'])\n",
    "\n",
    "    if deep_dive_data['false_positives']:\n",
    "        deep_dive_data['false_positives'] = pd.concat(deep_dive_data['false_positives'], ignore_index=True)\n",
    "    else:\n",
    "        deep_dive_data['false_positives'] = pd.DataFrame()\n",
    "\n",
    "    if deep_dive_data['false_negatives']:\n",
    "        deep_dive_data['false_negatives'] = pd.concat(deep_dive_data['false_negatives'], ignore_index=True)\n",
    "    else:\n",
    "        deep_dive_data['false_negatives'] = pd.DataFrame()\n",
    "\n",
    "    return full_summary_df, aggregate_summary_df, deep_dive_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8eaa28-0f97-46da-8028-832eb9f8fce8",
   "metadata": {},
   "source": [
    "# Execute Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288aa73-6789-49a2-9082-f056b820f4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
